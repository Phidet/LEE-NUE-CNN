""" Full assembly of the parts to form the complete network """
import torch.nn.functional as F
from unet_parts import *


class UNet(nn.Module):
    def __init__(self, n_channels, n_classes, depth):
        super(UNet, self).__init__()

        if (depth - 2) % 6 != 0:
            raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')

        num_filters = 16

        self.num_res_blocks = int((depth - 2) / 6) 
        self.input = DoubleConvNoResidual(n_channels, num_filters)
        self.input2 = DoubleConvNoResidual(num_filters, num_filters)

        self.DownLayers = nn.ModuleList()
        for stack in range(5):
            for res_block in range(self.num_res_blocks):
                if (stack > 0 and res_block == 0): # first layer but not first stack
                    self.DownLayers.append(Down(num_filters, 2*num_filters))
                    num_filters *= 2
                else:
                    self.DownLayers.append(DoubleConv2(num_filters, num_filters))

        self.UpLayers = nn.ModuleList()
        for stack in range(4):
            for res_block in range(self.num_res_blocks):
                if (res_block == 0): # first layer but not first stack
                    self.UpLayers.append(Up(num_filters, num_filters//2))
                    num_filters = int(num_filters//2)
                else:
                    self.UpLayers.append(DoubleConv3(num_filters, num_filters))
        self.output = OutConv(num_filters, n_classes)
        self.logSoftmax = nn.LogSoftmax(dim=1) # Normalises output over the channel dimension


    def forward(self, x):
        skips = []
        
        ####### Beginning of U-ResNet #######
        #####################################
        x = self.input(x)
        x = self.input2(x)
                
        ####### Beginning of Downsampling ResNet
        for i, layer in enumerate(self.DownLayers):
            x = layer(x)
            if(i%self.num_res_blocks==0):
                skips.append(x)
        ####### End of Downsampling ResNet
        
        ####### Beginning of Upsampling ResNet
        for i, layer in enumerate(self.UpLayers):
            if i%self.num_res_blocks==0:
                skip = skips[-2-(i//self.num_res_blocks)]
                x = layer(x, skip)
            else:
                x = layer(x)
        ####### End of Upsampling ResNet

        x = self.output(x)
        x = self.logSoftmax(x)
        return x


class UNet2(nn.Module):
    def __init__(self, n_channels, n_classes, depth):
        super(UNet2, self).__init__()

        if (depth - 2) % 6 != 0:
            raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')

        self.num_res_blocks = int((depth - 2) / 6) 
        
        self.input = DoubleConvNoResidual(n_channels, 16)

        self.dc_0_0 = DoubleConv2(16, 16)
        self.dc_0_1 = DoubleConv2(16, 16)
        self.dc_0_2 = DoubleConv2(16, 16)
        self.dc_0_3 = DoubleConv2(16, 16)
        self.dc_0_4 = DoubleConv2(16, 16)

        self.down_1 = Down(16, 32)
        self.dc_1_2 = DoubleConv2(32, 32)
        self.dc_1_0 = DoubleConv2(32, 32)
        self.dc_1_3 = DoubleConv2(32, 32)
        self.dc_1_1 = DoubleConv2(32, 32)

        self.down_2 = Down(32, 64)
        self.dc_2_0 = DoubleConv2(64, 64)
        self.dc_2_1 = DoubleConv2(64, 64)
        self.dc_2_2 = DoubleConv2(64, 64)
        self.dc_2_3 = DoubleConv2(64, 64)

        self.down_3 = Down(64, 128)
        self.dc_3_0 = DoubleConv2(128, 128)
        self.dc_3_1 = DoubleConv2(128, 128)
        self.dc_3_2 = DoubleConv2(128, 128)
        self.dc_3_3 = DoubleConv2(128, 128)

        self.down_4 = Down(128, 256)
        self.dc_4_0 = DoubleConv2(256, 256)
        self.dc_4_1 = DoubleConv2(256, 256)
        self.dc_4_2 = DoubleConv2(256, 256)
        self.dc_4_3 = DoubleConv2(256, 256)

        self.up_5   = Up(256, 128)
        self.dc_5_0 = DoubleConv2(128, 128)
        self.dc_5_1 = DoubleConv2(128, 128)
        self.dc_5_2 = DoubleConv2(128, 128)
        self.dc_5_3 = DoubleConv2(128, 128)

        self.up_6   = Up(128, 64)
        self.dc_6_0 = DoubleConv2(64, 64)
        self.dc_6_1 = DoubleConv2(64, 64)
        self.dc_6_2 = DoubleConv2(64, 64)
        self.dc_6_3 = DoubleConv2(64, 64)

        self.up_7   = Up(64, 32)
        self.dc_7_0 = DoubleConv2(32, 32)
        self.dc_7_1 = DoubleConv2(32, 32)
        self.dc_7_2 = DoubleConv2(32, 32)
        self.dc_7_3 = DoubleConv2(32, 32)

        self.up_8   = Up(32, 16)
        self.dc_8_0 = DoubleConv2(16, 16)
        self.dc_8_1 = DoubleConv2(16, 16)
        self.dc_8_2 = DoubleConv2(16, 16)
        self.dc_8_3 = DoubleConv2(16, 16)

        self.output = OutConv(16, 3)
        self.logSoftmax = nn.LogSoftmax(dim=1) # Normalises output over the channel dimension


    def forward(self, x):
        
        ####### Beginning of U-ResNet #######
        #####################################
        x0 = self.input(x)
        
        x1 = self.dc_0_0(x0)
        x1 = self.dc_0_1(x1)
        x1 = self.dc_0_2(x1)
        x1 = self.dc_0_3(x1)
        x1 = self.dc_0_4(x1)

        x2 = self.down_1(x1)
        x2 = self.dc_1_2(x2)
        x2 = self.dc_1_0(x2)
        x2 = self.dc_1_3(x2)
        x2 = self.dc_1_1(x2)

        x3 = self.down_2(x2)
        x3 = self.dc_2_0(x3)
        x3 = self.dc_2_1(x3)
        x3 = self.dc_2_2(x3)
        x3 = self.dc_2_3(x3)

        x4 = self.down_3(x3)
        x4 = self.dc_3_0(x4)
        x4 = self.dc_3_1(x4)
        x4 = self.dc_3_2(x4)
        x4 = self.dc_3_3(x4)

        x5 = self.down_4(x4)
        x5 = self.dc_4_0(x5)
        x5 = self.dc_4_1(x5)
        x5 = self.dc_4_2(x5)
        x5 = self.dc_4_3(x5)

        y = self.up_5(x5, x4)
        y = self.dc_5_0(y)
        y = self.dc_5_1(y)
        y = self.dc_5_2(y)
        y = self.dc_5_3(y)

        y = self.up_6(y, x3)
        y = self.dc_6_0(y)
        y = self.dc_6_1(y)
        y = self.dc_6_2(y)
        y = self.dc_6_3(y)

        y = self.up_7(y, x2)
        y = self.dc_7_0(y)
        y = self.dc_7_1(y)
        y = self.dc_7_2(y)
        y = self.dc_7_3(y)

        y = self.up_8(y, x1)
        y = self.dc_8_0(y)
        y = self.dc_8_1(y)
        y = self.dc_8_2(y)
        y = self.dc_8_3(y)

        y = self.output(y)
        y = self.logSoftmax(y)
        return y